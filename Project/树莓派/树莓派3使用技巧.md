## Linux命令行烧录树莓派镜像至SD卡

查找SD卡

运行df -h命令查看当前哪些设备已经挂载，结果如下图第一次显示。只执行 df 命令也是可以的，但是-h选项给出的分区大小更加直观易读，h是human的缩写。插入SD卡后，再次运行 df -h，找出两次运行区别。如下图：我们插入的SD卡设备名称就是/dev/sdb它包含两个分区，分别是/dev/sdb1 和 /dev/sdb2。注意下面我们要在“设备”中写入镜像，而不是只向某个分区写入。

![20131208231703527-0](http://shumeipai.nxez.com/wp-content/uploads/2013/12/20131208231703527-0.jpg)

为了防止在写入镜像的时候有其他读取或写入，我们需要卸载设备。两个分区都要卸载。

```
`umount` `/dev/sdb1``umount` `/dev/sdb2`
```

使用dd命令写入镜像至SD卡

bs代表一次写入多大的块，是blocksize的缩写，4M一般都没问题，如果不行，试试改成1M，if参数为下载的镜像的路径（应该是input file缩写），of后参数为设备地址（应该是output file的缩写，linux上一切都是文件）千万不要写错这里的参数，否这你可能丢失硬盘所有数据。

```shell
`sudo` `dd` `bs=4M ``if``=2013-09-25-wheezy-raspbian.img of=``/dev/sdb`
```

当然如果你非常想看到此时的拷贝进度也是可以的。打开另一个命令行执行

```shell
`sudo` `pkill -USR1 -n -x ``dd`
```

![20131208231703416-0](http://shumeipai.nxez.com/wp-content/uploads/2013/12/20131208231703416-0.jpg)



### 探测同一网段下，树莓派的 ip

```shell
$ arp raspberrypi
Address                  HWtype  HWaddress           Flags Mask            Iface
raspberrypi              ether   b8:27:eb:68:77:60   C                     wlp2s0
$ arp -a raspberrypi
raspberrypi (192.168.43.236) at b8:27:eb:68:77:60 [ether] on wlp2s0
```

### 使用标准USB网络摄像头

您可以使用标准USB网络摄像头在Raspberry Pi上拍摄照片和视频，而不是使用Raspberry Pi [相机模块](https://www.raspberrypi.org/documentation/usage/camera/README.md)。

请注意，相机模块的质量和可配置性远高于标准USB网络摄像头。

### 安装 fswebcam

首先，安装`fswebcam`包：

```bash
sudo apt-get install fswebcam
```

## 基本用法

输入命令`fswebcam`后跟文件名，将使用网络摄像头拍摄照片，并保存到指定的文件名：

```bash
fswebcam image.jpg
```

![基本图像捕获](https://www.raspberrypi.org/documentation/usage/webcams/images/image.jpg)

请注意使用的小默认分辨率，以及显示时间戳的横幅的存在。

### 指定分辨率

此示例中使用的网络摄像头的分辨率为`1280 x 720`，以指定我想要拍摄图像的分辨率，使用`-r`标志：

```bash
fswebcam -r 1280x720 image2.jpg
```

![全分辨率图像](https://www.raspberrypi.org/documentation/usage/webcams/images/image2.jpg)

图片现在以网络摄像头的全分辨率拍摄，并显示横幅。

### 不指定横幅

现在添加`--no-banner`标志：

```bash
fswebcam -r 1280x720 --no-banner image3.jpg
```

![没有横幅的全分辨率图像](https://www.raspberrypi.org/documentation/usage/webcams/images/image3.jpg)

现在照片是全分辨率拍摄的，没有横幅。

## 糟糕的图片

使用USB网络摄像头可能会遇到质量差的图片，例如这个意外的艺术作品：

![坏网络摄像头图片](https://www.raspberrypi.org/documentation/usage/webcams/images/jack.jpg)

有些网络摄像头比其他网络摄像头更可靠，但这种问题可能会出现质量不佳的网络摄像头。如果问题仍然存在，请确保您的系统是[最新的](https://www.raspberrypi.org/documentation/raspbian/updating.md)。另外尝试其他网络摄像头，但您将从Raspberry Pi [相机模块](https://www.raspberrypi.org/help/camera-module-setup/)获得最佳性能。

## Bash脚本

您可以编写一个Bash脚本，用于拍摄网络摄像头。下面的脚本将图像保存在`/home/pi/webcam`目录中，因此`webcam`首先使用以下命令创建子目录：

```bash
mkdir webcam
```

要创建脚本，请打开您选择的编辑器并编写以下示例代码：

```bash
#!/bin/bash

DATE=$(date +"%Y-%m-%d_%H%M")

fswebcam -r 1280x720 --no-banner /home/pi/webcam/$DATE.jpg
```

此脚本将拍摄照片并使用时间戳命名该文件。假设我们保存它`webcam.sh`，我们首先使文件可执行：

```bash
chmod +x webcam.sh
```

然后运行：

```bash
./webcam.sh
```

哪个会在文件中运行命令并提供通常的输出：

```
--- Opening /dev/video0...
Trying source module v4l2...
/dev/video0 opened.
No input was specified, using the first.
--- Capturing frame...
Corrupt JPEG data: 2 extraneous bytes before marker 0xd6
Captured frame in 0.00 seconds.
--- Processing captured image...
Disabling banner.
Writing JPEG image to '/home/pi/webcam/2013-06-07_2338.jpg'.
```

## 延时使用cron

您可以使用`cron`计划以给定间隔（例如每分钟）拍摄照片以捕捉延时。

首先打开cron表进行编辑：

```
crontab -e
```

这将询问您要使用哪个编辑器，或者在默认编辑器中打开。在编辑器中打开文件后，添加以下行以安排每分钟拍照（参考上面的Bash脚本）：

```bash
* * * * * /home/pi/webcam.sh 2>&1
```

保存并退出，您应该看到以下消息：

```bash
crontab: installing new crontab
```

确保您的脚本不保存使用相同文件名拍摄的每张照片。这将每次覆盖图片。

## 其他有用的工具

使用相机或网络摄像头时，可以使用其他工具：

- SSH
  - 使用SSH通过本地网络远程访问Raspberry Pi
- SCP
  - 通过SSH复制文件以获取主计算机上Pi上拍摄的照片的副本
- rsync的
  - 用于`rsync`将Pi中文件夹中拍摄的照片文件夹与计算机同步
- cron的
  - 使用`cron`安排拍照在给定的时间间隔，例如每分钟拍摄时间推移



## 树莓派 vnc 调整分辨率

   树莓派3在使用vnc的时候分辨率特别低，甚至无法显示整个桌面，所以需要对vnc登录的分辨率进行设置。其实在树莓派3上设置vnc的分辨率很简单，只需要用raspberry-config命令就能设置。

       设置方法是在终端输入：sudo raspberry-config 命令，然后按下面的顺序选择分辨率设置 Advanced Options > Resolution。



### 安装树莓派摄像头模块

按照以下步骤来将树莓派摄像头模块连接搭配树莓派：

1. 找到 CSI 接口(CSI接口在以太网接口旁边)，掀起深色胶带。
2. 拉起 CSI 接口挡板。
3. 拿起你的摄像头模块，将贴在镜头上的塑料保护膜撕掉。确保黄色部分的PCB(有字的一面)是安装完美的（可以轻轻按一下黄色的部分来保证安装完美）。
4. 将排线插入CSI接口。记住，有蓝色胶带的一面应该面向以太网接口方向。同样，这时也确认一下排线安装好了之后，将挡板拉下。

![img](https://dn-linuxcn.qbox.me/data/attachment/album/201408/21/130426pxvuxrqtnpppxx17.jpg)

好了，现在你的 Pi Cam 已经准备就绪，可以拍摄照片或视频了。

### 在树莓派上启用摄像头模块

在安装完摄像头模块之后，首先要确认你已经升级了树莓派系统并应用了最新的固件。可以输入以下命令来操作：

```
$ sudo apt-get update
$ sudo apt-get upgrade 
```

运行树莓派配置工具来激活摄像头模块：

```
$ sudo raspi-config 
```

移动光标至菜单中的 "Enable Camera（启用摄像头）"，将其设为Enable（启用状态）。完成之后重启树莓派。

![img](https://dn-linuxcn.qbox.me/data/attachment/album/201408/21/130440dguwh6gwk1vk9jgv.jpg)

安装完摄像头模块后的完成照：

![img](https://dn-linuxcn.qbox.me/data/attachment/album/201408/21/130454br44z4dnp2c3zcyr.jpg)

### 通过摄像头模块拍照

在重启完树莓派后，我们就可以使用Pi Cam了。要用它来拍摄照片的话，可以从命令行运行raspistill：

```
$ raspistill -o keychain.jpg -t 2000 
```

这句命令将在 2000ms 后拍摄一张照片，然后保存为 keychain.jpg。下面就是一张由 Pi Cam 拍摄的我的小熊公仔钥匙链。

![img](https://dn-linuxcn.qbox.me/data/attachment/album/201408/21/130456h516ypyamyo5mst6.jpg)

raspiyuv 工具用法差不多，只不过拍摄得到的是一张未处理过的raw图像。

### 通过摄像头模块拍视频

想要用摄像头模块拍一段视频的话，可以从命令行运行 raspivid 工具。下面这句命令会按照默认配置(长度5秒，分辨率1920x1080，比特率 17Mbps)拍摄一段视频。

```
$ raspivid -o mykeychain.h264
```

如果你想改变拍摄时长，只要通过 "-t" 选项来设置你想要的长度就行了（单位是毫秒）。

```
$ raspivid -o mykeychain.h264 -t 10000
```

使用 "-w" 和 "-h" 选项将分辨率降为 1280x720...

```
$ raspivid -o mykeychain.h264 -t 10000 -w 1280 -h 720
```

raspivid 的输出是一段未压缩的 H.264 视频流，而且这段视频不含声音。为了能被通常的视频播放器所播放，这个 raw 的 H.264 视频还需要转换。可以使用 gpac 包中所带有的 MP4Box 应用。

在 Raspbian 上安装 gpac，输入命令：

```
$ sudo apt-get install -y gpac 
```

然后将这段 raw 的 H.264 格式的视频流转换为每秒30帧的 .mp4 格式视频：

```
$ MP4Box -fps 30 -add keychain.h264 keychain.mp4 
```



树莓派3在使用vnc的时候分辨率特别低，甚至无法显示整个桌面，所以需要对vnc登录的分辨率进行设置。其实在树莓派3上设置vnc的分辨率很简单，只需要用raspberry-config命令就能设置。

设置方法是在终端输入：sudo raspberry-config 命令，然后选择分辨率设置 Advanced Options > Resolution，选择合适的分辨率(如1920*1080)

最后 reboot 重启树莓派即可.



## 安装 Tensorflow lite：

https://www.tensorflow.org/lite/rpi

# TensorFlow Lite for Raspberry Pi

## Cross compiling

### Installing the toolchain

This has been tested on Ubuntu 16.04.3 64bit and Tensorflow devel docker image [tensorflow/tensorflow:nightly-devel](https://hub.docker.com/r/tensorflow/tensorflow/tags/).

To cross compile TensorFlow Lite, first install the toolchain and libs.

```bash
sudo apt-get update
sudo apt-get install crossbuild-essential-armhf
```

> If you are using Docker, you may not use `sudo`.

### Building

Clone this Tensorflow repository, Run this script at the root of the repository to download all the dependencies:

> The Tensorflow repository is in `/tensorflow` if you are using `tensorflow/tensorflow:nightly-devel` docker image, just try it.

```bash
./tensorflow/contrib/lite/tools/make/download_dependencies.sh
```

Note that you only need to do this once.

You should then be able to compile:

```bash
./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh
```

This should compile a static library in: `tensorflow/contrib/lite/gen/lib/rpi_armv7/libtensorflow-lite.a`.

## Native compiling

This has been tested on Raspberry Pi 3b, Raspbian GNU/Linux 9.1 (stretch), gcc version 6.3.0 20170516 (Raspbian 6.3.0-18+rpi1).

Log in to you Raspberry Pi, install the toolchain.

```bash
sudo apt-get install build-essential
```

download the repository：

```shell
git clone https://github.com/tensorflow/tensorflow.git
```

First, clone the TensorFlow repository. Run this at the root of the repository:

```bash
./tensorflow/contrib/lite/tools/make/download_dependencies.sh
```

Note that you only need to do this once.

You should then be able to compile:

```bash
./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh
```

This should compile a static library in:`tensorflow/contrib/lite/tools/make/gen/lib/rpi_armv7/libtensorflow-lite.a`.

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see our [Site Policies](https://developers.google.com/terms/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated September 27, 2018.